import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import io
import math
import re
import csv
import numpy as np
import plotly.express as px
from io import BytesIO
from matplotlib.dates import DateFormatter
from datetime import datetime, timedelta
from plotly.graph_objs import Scatter, Layout, Figure
from collections import Counter
from collections import Counter, defaultdict
from st_aggrid import AgGrid, GridOptionsBuilder


st.write(
    """  
    <p style="color:blue; font-size:40px; font-weight:bold;">Gen-song</p>  
    """,
    unsafe_allow_html=True
)


file_groups = defaultdict(list)
# åœ¨ä¾§è¾¹æ ä¸­åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ä¸Šä¼ æ§ä»¶
uploaded_files = st.sidebar.file_uploader('è¯·ä¸Šä¼  CSV æ–‡ä»¶', type=['csv'],  accept_multiple_files=True)

# åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„DataFrameæ¥ä¿å­˜æ‰€æœ‰æ•°æ®
all_data = pd.DataFrame()
if uploaded_files:
    row_count = 0
    column_order = ['åºå·', 'æ–‡ä»¶å','SNå·','å¼€å§‹æ—¶é—´', 'ç»“æŸæ—¶é—´', 'ä»»åŠ¡æ‰§è¡Œç”¨æ—¶(s)', 'åœè½¦æ¬¡æ•°',
                    'æ•…éšœç¼–å·', 'æ•…éšœå‡ºç°æ¬¡æ•°', 'æ•…éšœå‡ºç°æ—¶é—´æ®µ', 'æœ€å¤§æ¨ªå‘åå·®(mm)',
                    'æœ€å¤§èˆªå‘åå·®*10(Â°)', 'å¹³å‡é€Ÿåº¦ï¼ˆmm/sï¼‰', 'å¹³å‡çº åé‡ï¼ˆÂ°ï¼‰', 'æœ€å¤§çº åé‡ï¼ˆÂ°ï¼‰',
                    'åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)', 'ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)','ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)','ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆåé€€ï¼‰',
                    'ç»ˆç‚¹è·¯çº¿å·ï¼ˆåé€€ï¼‰','ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆåé€€ï¼‰',
                    'åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)', 'ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)','ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)', 'ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆå‰è¿›ï¼‰',
                    'ç»ˆç‚¹è·¯çº¿å·ï¼ˆå‰è¿›ï¼‰' ,'ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆå‰è¿›ï¼‰']

    for uploaded_file in uploaded_files:

        with uploaded_file as file:

            df = pd.read_csv(file, skiprows=2, on_bad_lines='skip' )


            #æ£€æŸ¥ä¸Šä¼ çš„csvæ–‡ä»¶æ˜¯å¦æœ‰è‡ªåŠ¨ä»»åŠ¡æ•°æ®
            if 'LogType' in df.columns:
                if 10 not in df['LogType'].unique():
                    st.write(f"æ–‡ä»¶ {uploaded_file.name} ä¸­æ— æ•°æ®oræ ¼å¼é”™è¯¯")
                    continue  # è·³è¿‡å½“å‰å¾ªç¯çš„å‰©ä½™éƒ¨åˆ†ï¼Œå¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶


        df['Time'] = pd.to_datetime(df['Time'], format='%Y-%m-%d %H:%M:%S:%f', errors='coerce')


        # æå–æ–‡ä»¶åä¸­çš„SNå·
        filename = uploaded_file.name
        sn_number = ''
        if '-' in filename:
            parts = filename.split('-')
            if len(parts) > 1:

                sn_candidate = parts[0]
                if len(sn_candidate) >= 12:
                    sn_number = sn_candidate


        filtered_df = df
        special_points = []
        start_time = None
        end_time = None
        parking_count = 0

        # æ£€æŸ¥ MotorCommand_SteeringAngle1 åˆ—æ˜¯å¦å­˜åœ¨
        steering_angle_column_exists = 'MotorCommand_SteeringAngle1' in filtered_df.columns

        # æ ¹æ®åˆ—æ˜¯å¦å­˜åœ¨æ¥è®¾ç½®route_numberçš„ç´¢å¼•
        route_number_index = 42 if steering_angle_column_exists else 52  # å‡è®¾ç¬¬53åˆ—æ˜¯route_numberï¼ˆç´¢å¼•ä»0å¼€å§‹ï¼‰

        # åœæ­¢ç²¾åº¦ç›¸å…³æ•°æ®å¤„ç†
        prev_100_speeds = []
        prev_log_type_was_10 = False

        for index, row in filtered_df.iterrows():
            log_type = row['LogType']
            remain_distance = row['RemainDistance']
            route_number = row.iloc[route_number_index]
            lateral_error = row.iloc[9]
            attitude_error = row.iloc[10]
            motor_speed = row['MotorStatus_MotorSpeed1']


            if len(prev_100_speeds) < 100:
                prev_100_speeds.append(motor_speed)
            else:
                prev_100_speeds.pop(0)
                prev_100_speeds.append(motor_speed)


            if not (-150 < remain_distance < 150):
                continue

            # å‰ä¸€ä¸ªLogTypeæ˜¯10ï¼Œè€Œå½“å‰ä¸æ˜¯ï¼Œé‚£ä¹ˆè®°å½•å‰ä¸€ä¸ªç‚¹çš„ä¿¡æ¯
            if prev_log_type_was_10 and log_type != 10:
                prev_row = filtered_df.iloc[index - 1]
                prev_remain_distance = prev_row['RemainDistance']
                prev_route_number = prev_row.iloc[route_number_index]
                prev_lateral_error = prev_row.iloc[9]
                prev_attitude_error = prev_row.iloc[10]

                
                forward_or_backward = "æœªçŸ¥"
                if any(speed > 0 for speed in prev_100_speeds):
                    forward_or_backward = "å‰è¿›"
                elif any(speed < 0 for speed in prev_100_speeds):
                    forward_or_backward = "åé€€"

                # æ„å»ºhovertextå­—ç¬¦ä¸²
                hover_text = f"{forward_or_backward}/"
                if prev_remain_distance > 0:
                    hover_text += "æœªåˆ°ç‚¹"
                elif prev_remain_distance < 0:
                    hover_text += "è¿‡å†²"

                special_points.append((
                    prev_row['Time'],
                    prev_remain_distance,
                    prev_route_number,
                    prev_lateral_error,
                    prev_attitude_error,
                    hover_text
                ))

            prev_log_type_was_10 = log_type == 10

        # æ•…éšœç›¸å…³æ•°æ®å¤„ç†
        # ç¡®ä¿ErrorCodeåˆ—å­˜åœ¨(æ•…éšœä¾‹ï¼‰
        if 'ErrorCode' in df.columns:


            fault_counter = Counter()
            fault_status = {}
            fault_times = defaultdict(lambda: {'occurrences': []})  # ä¿®æ”¹æ­¤å¤„ä»¥å­˜å‚¨æ‰€æœ‰çš„å‡ºç°æ—¶é—´æ®µ

            # è·å–DataFrameçš„æ€»è¡Œæ•°
            total_rows = len(df)

            # éå†ErrorCodeåˆ—
            for index, row in df.iterrows():
                error_code = row['ErrorCode']
                time_stamp = row['Time']

                # å¦‚æœErrorCodeä¸ºç©ºæˆ–è€…ä¸ºNaNï¼Œåˆ™è·³è¿‡
                if pd.isnull(error_code) or not isinstance(error_code, int):
                    continue

                    # å°†é”™è¯¯ç è½¬æ¢ä¸ºäºŒè¿›åˆ¶å½¢å¼
                binary_representation = bin(error_code)[2:]

                for i, bit in enumerate(reversed(binary_representation)):
                    fault_number = i + 1

                    # å¦‚æœå½“å‰ä½æ˜¯1ï¼Œåˆ™æ•…éšœå­˜åœ¨
                    if bit == '1':
                        if fault_number not in fault_status or not fault_status[fault_number]:
                            # å¦‚æœæ•…éšœä¹‹å‰ä¸å­˜åœ¨æˆ–å·²ç»è§£å†³ï¼Œåˆ™å¢åŠ è®¡æ•°
                            fault_counter[fault_number] += 1
                            # æ›´æ–°æ•…éšœçŠ¶æ€ä¸ºæ¿€æ´»
                            fault_status[fault_number] = True
                            # è®°å½•æ•…éšœé¦–æ¬¡å‡ºç°çš„æ—¶é—´
                            fault_times[fault_number]['occurrences'].append(
                                {'first_seen': time_stamp, 'last_seen': time_stamp})
                        else:
                            # æ›´æ–°å½“å‰å‡ºç°çš„æ•…éšœçš„æœ€åæ—¶é—´
                            fault_times[fault_number]['occurrences'][-1]['last_seen'] = time_stamp
                    else:
                        if fault_number in fault_status and fault_status[fault_number]:
                            fault_status[fault_number] = False

            # åˆå§‹åŒ–èšåˆå˜é‡
            aggregated_fault_numbers = []
            total_occurrences = 0
            time_ranges_combined = []

            # èšåˆæ•…éšœæ•°æ®
            for fault_number, count in fault_counter.items():
                occurrences = fault_times[fault_number]['occurrences']
                time_ranges = [
                    "{}--{}".format(occ['first_seen'].strftime('%H:%M:%S'), occ['last_seen'].strftime('%H:%M:%S')) for
                    occ in occurrences]
                time_ranges_combined.extend(time_ranges)

                prefix = '70' if fault_number >= 10 else '700'
                prefixed_fault_number = prefix + str(fault_number)
                aggregated_fault_numbers.append(prefixed_fault_number)
                total_occurrences += count

            # å°†æ—¶é—´æ®µåˆ—è¡¨è½¬æ¢ä¸ºå•ä¸ªå­—ç¬¦ä¸²
            time_range_str_combined = ", ".join(time_ranges_combined)

        # è®¡ç®—æœ€å¤§æ¨ªå‘åå·®å’Œæœ€å¤§èˆªå‘åå·®çš„é€»è¾‘
        lateral_errors = [point[3] for point in special_points]
        attitude_errors_rad = [point[4] for point in special_points]
        attitude_errors_deg = [math.degrees(error) * 10 for error in attitude_errors_rad]

        max_lateral_error_index = max(range(len(lateral_errors)), key=lambda i: abs(lateral_errors[i]))
        max_attitude_error_index = max(range(len(attitude_errors_deg)), key=lambda i: abs(attitude_errors_deg[i]))

        max_lateral_error = lateral_errors[max_lateral_error_index]
        max_attitude_error = attitude_errors_deg[max_attitude_error_index]

        # ç¡®å®šå¼€å§‹æ—¶é—´å’Œç»“æŸæ—¶é—´
        for index, row in filtered_df.iterrows():
            log_type = row['LogType']
            if log_type in [10, 12, 13, 14]:
                if start_time is None:
                    start_time = row['Time']  # è®¾ç½®å¼€å§‹æ—¶é—´
                end_time = row['Time']  # æ›´æ–°ç»“æŸæ—¶é—´ä¸ºå½“å‰æ—¶é—´æˆ³
        # å¦‚æœå¼€å§‹æ—¶é—´å’Œç»“æŸæ—¶é—´éƒ½æä¾›äº†ï¼Œåˆ™è®¡ç®—æ‰§è¡Œç”¨æ—¶
        if start_time and end_time:
            execution_time = end_time - start_time
            # å°†æ‰§è¡Œç”¨æ—¶è½¬æ¢ä¸ºç§’
            execution_time_seconds = execution_time.total_seconds()

        # æ ¹æ®å¼€å§‹æ—¶é—´å’Œç»“æŸæ—¶é—´ç­›é€‰æ•°æ®
        masked_df = filtered_df[(filtered_df['Time'] >= start_time) & (filtered_df['Time'] <= end_time)]

        # è®¡ç®—å¹³å‡é€Ÿåº¦
        average_speed = masked_df['MotorStatus_MotorSpeed1'].mean()

        # æ£€æŸ¥çº åé‡æ‰€éœ€çš„åˆ—æ˜¯å¦å­˜åœ¨
        if 'MotorCommand_SteeringAngle1' in masked_df.columns:
            # è®¡ç®—çº åé‡
            masked_df['Deviation'] = masked_df['MotorCommand_SteeringAngle1'] - masked_df['NominalCtrlOutput']

            # è®¡ç®—å¹³å‡çº åé‡
            average_deviation = masked_df['Deviation'].mean()

            # è®¡ç®—æœ€å¤§çº åé‡ï¼ˆä¿ç•™æ­£è´Ÿå·ï¼‰
            max_deviation_index = masked_df['Deviation'].abs().idxmax()
            max_deviation_value = masked_df.at[max_deviation_index, 'Deviation']
        else:
            average_deviation = 0
            max_deviation_value = 0


        # æ·»åŠ è·¯çº¿ç±»å‹åˆ¤æ–­çš„å‡½æ•°
        def get_route_type(df, point_time, angle_column='MotorStatus_SteeringAngle1', window_size=200):
            if angle_column not in df.columns:
                # å¦‚æœåˆ—ä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›'ç›´çº¿'
                return 'ç›´çº¿'
            # è·å–ç‚¹æ—¶é—´çš„ç´¢å¼•
            point_index = df[df['Time'] == point_time].index[0]
            # è·å–å‰window_sizeè¡Œçš„è§’åº¦æ•°æ®
            angles = df.loc[point_index - window_size:point_index, angle_column]
            # æ£€æŸ¥æ˜¯å¦æœ‰è§’åº¦å¤§äº10æˆ–å°äº-10
            if angles.max() > 10 or angles.min() < -10:
                return 'å¼¯é“'
            else:
                return 'ç›´çº¿'


        # åœæ­¢ç²¾åº¦ç›¸å…³æ•°æ®é‡å¤„ç†
        forward_stop_accuracies = []
        backward_stop_accuracies = []
        forward_lateral_deviations = []
        forward_heading_deviations = []
        backward_lateral_deviations = []
        backward_heading_deviations = []
        forward_statuses = []
        backward_statuses = []
        forward_route_numbers = []
        backward_route_numbers = []
        forward_route_types = []
        backward_route_types = []

        # éå†ç‰¹æ®Šç‚¹
        for point in special_points:
            route_number = str(point[2])[-5:]  # å–è·¯çº¿å·çš„åäº”ä½
            status = point[5]  # çŠ¶æ€ä¿¡æ¯
            stop_accuracy = round(point[1], 2)  # åœæ­¢ç²¾åº¦ä¿ç•™ä¸¤ä½å°æ•°
            lateral_deviation = round(point[3], 2)  # ç»ˆç‚¹æ¨ªå‘åå·®
            heading_deviation = round(math.degrees(point[4]), 2)  # ç»ˆç‚¹èˆªå‘åå·®è½¬æ¢ä¸ºåº¦æ•°å¹¶ä¿ç•™ä¸¤ä½å°æ•°
            stop_time = point[0]
            # åˆ¤æ–­è·¯çº¿ç±»å‹
            route_type = get_route_type(df, stop_time)

            # æ ¹æ®çŠ¶æ€å°†åœæ­¢ç²¾åº¦å’Œå…¶ä»–æ•°æ®åˆ†ç±»åˆ°å‰è¿›æˆ–åé€€åˆ—è¡¨ä¸­
            if 'å‰è¿›' in status:
                forward_stop_accuracies.append(stop_accuracy)
                forward_lateral_deviations.append(lateral_deviation)
                forward_heading_deviations.append(heading_deviation)
                forward_statuses.append(status.replace('å‰è¿›/', ''))
                forward_route_numbers.append(route_number)
                forward_route_types.append(route_type)
            elif 'åé€€' in status:
                backward_stop_accuracies.append(stop_accuracy)
                backward_lateral_deviations.append(lateral_deviation)
                backward_heading_deviations.append(heading_deviation)
                backward_statuses.append(status.replace('åé€€/', ''))
                backward_route_numbers.append(route_number)
                backward_route_types.append(route_type)


        # è½¬æ¢åˆ—è¡¨ä¸ºå­—ç¬¦ä¸²ï¼Œç”¨äºåç»­çš„æ•°æ®å±•ç¤ºæˆ–å­˜å‚¨
        def list_to_str(lst):
            return ' ; '.join(map(str, lst)) if lst else ''

        data = {
            'æ–‡ä»¶å': uploaded_file.name,
            'SNå·': [sn_number],
            'å¼€å§‹æ—¶é—´': [start_time] if start_time else [],
            'ç»“æŸæ—¶é—´': [end_time] if end_time else [],
            'ä»»åŠ¡æ‰§è¡Œç”¨æ—¶(s)': round(execution_time_seconds, 2),
            'åœè½¦æ¬¡æ•°': [len(special_points)],
            'æ•…éšœç¼–å·': ", ".join(aggregated_fault_numbers),
            'æ•…éšœå‡ºç°æ¬¡æ•°': total_occurrences,
            'æ•…éšœå‡ºç°æ—¶é—´æ®µ': time_range_str_combined,
            'æœ€å¤§æ¨ªå‘åå·®(mm)': [round(max_lateral_error, 2)],
            'æœ€å¤§èˆªå‘åå·®*10(Â°)': [round(max_attitude_error, 2)],
            'å¹³å‡é€Ÿåº¦ï¼ˆmm/sï¼‰': [round(average_speed, 2)],
            'å¹³å‡çº åé‡ï¼ˆÂ°ï¼‰': [round(average_deviation, 2)],
            'æœ€å¤§çº åé‡ï¼ˆÂ°ï¼‰': [round(max_deviation_value, 2)],
            'åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)': list_to_str(backward_stop_accuracies),
            'ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)': list_to_str(backward_lateral_deviations),
            'ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)': list_to_str(backward_heading_deviations),
            'ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆåé€€ï¼‰': list_to_str(backward_statuses),
            'ç»ˆç‚¹è·¯çº¿å·ï¼ˆåé€€ï¼‰': list_to_str(backward_route_numbers),
            'ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆåé€€ï¼‰': '; '.join(backward_route_types),
            'åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)': list_to_str(forward_stop_accuracies),
            'ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)': list_to_str(forward_lateral_deviations),
            'ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)': list_to_str(forward_heading_deviations),
            'ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆå‰è¿›ï¼‰': list_to_str(forward_statuses),
            'ç»ˆç‚¹è·¯çº¿å·ï¼ˆå‰è¿›ï¼‰': list_to_str(forward_route_numbers),
            'ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆå‰è¿›ï¼‰': '; '.join(forward_route_types),
        }

        # å°†å­—å…¸è½¬æ¢ä¸ºDataFrame
        temp_df = pd.DataFrame(data)
        temp_df = temp_df.reindex(columns=column_order)
        # å¡«å……åºå·
        row_count += 1
        temp_df.at[0, 'åºå·'] = row_count
        all_data = pd.concat([all_data, temp_df], ignore_index=True)


        def extract_key_number(filename):
            match = re.search(r'-(\d+)-[^-]+-(\d+)', filename)
            if match:
                return match.group(2)
            return -1


        all_data['key_numbers'] = all_data['æ–‡ä»¶å'].apply(extract_key_number)

        # åˆ›å»ºä¸€ä¸ªç©ºDataFrameç”¨äºå­˜å‚¨èšåˆåçš„æ•°æ®
        aggregated_data = pd.DataFrame()

        # ç­›é€‰å‡ºä¸å«'idle'çš„æ–‡ä»¶è¿›è¡Œåˆ†ç»„å’Œèšåˆ
        non_idle_data = all_data[~all_data['æ–‡ä»¶å'].str.contains('idle', na=False)]
        if not non_idle_data.empty:
            # è¿‡æ»¤æ‰æ²¡æœ‰åŒ¹é…å…³é”®æ•°å­—çš„è¡Œ
            non_idle_data = non_idle_data.dropna(subset=['key_numbers'])



            def max_abs_with_sign(series):
                max_abs_idx = np.abs(series).idxmax()
                return series[max_abs_idx]

            def aggregate_rows(group):

                # å­—ç¬¦ä¸²åˆ—ï¼Œä½¿ç”¨é€—å·è¿æ¥
                string_cols = ['æ–‡ä»¶å','SNå·' ]
                string_dict = {col: ', '.join(group[col].unique()) for col in string_cols}

                # æ•°å­—åˆ—ï¼Œæ±‚å’Œ
                numeric_cols = ['åœè½¦æ¬¡æ•°', 'ä»»åŠ¡æ‰§è¡Œç”¨æ—¶(s)', 'æ•…éšœå‡ºç°æ¬¡æ•°']
                numeric_dict = {col: group[col].sum() if col in group.columns else None for col in numeric_cols}

                # å•å€¼åˆ—ï¼ˆä¸æ˜¯åˆ—è¡¨ï¼‰ï¼Œä¿ç•™å¹³å‡æ•°
                single_value_list_cols = ['å¹³å‡é€Ÿåº¦ï¼ˆmm/sï¼‰', 'å¹³å‡çº åé‡ï¼ˆÂ°ï¼‰']
                single_value_list_dict = {
                    col: round(group[col].mean(), 2) if col in group.columns and not group[col].empty else None for col in
                    single_value_list_cols}

                #å•å€¼åˆ—ï¼Œä¿ç•™ç»å¯¹å€¼æœ€å¤§æ•°
                max_value_cols = [
                    'æœ€å¤§æ¨ªå‘åå·®(mm)', 'æœ€å¤§èˆªå‘åå·®*10(Â°)', 'æœ€å¤§çº åé‡ï¼ˆÂ°ï¼‰'
                ]
                max_value_dict = {col: max_abs_with_sign(group[col].dropna()) for col in max_value_cols}

                #å¤šå€¼åˆ—ï¼Œä½¿ç”¨åˆ†å·è¿æ¥
                multi_value_list_cols = [
                    'åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)', 'ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)', 'ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)', 'ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆåé€€ï¼‰', 'ç»ˆç‚¹è·¯çº¿å·ï¼ˆåé€€ï¼‰',
                    'åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)', 'ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)', 'ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)', 'ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆå‰è¿›ï¼‰', 'ç»ˆç‚¹è·¯çº¿å·ï¼ˆå‰è¿›ï¼‰'
                    , 'ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆåé€€ï¼‰', 'ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆå‰è¿›ï¼‰' ,'æ•…éšœç¼–å·', 'æ•…éšœå‡ºç°æ—¶é—´æ®µ'
                ]
                multi_value_list_dict = {
                    col: '; '.join(
                        item for sublist in group[col].dropna().tolist() for item in sublist.split(';') if item)
                    for col in multi_value_list_cols
                }

                # å¼€å§‹æ—¶é—´å’Œç»“æŸæ—¶é—´å¤„ç†
                time_cols = ['å¼€å§‹æ—¶é—´', 'ç»“æŸæ—¶é—´']

                # é¦–å…ˆï¼Œç¡®ä¿æ—¶é—´åˆ—æ˜¯datetimeç±»å‹
                for col in time_cols:
                    group[col] = pd.to_datetime(group[col], format='%d/%m/%Y %H:%M',
                                                errors='coerce')  # errors='coerce'ä¼šå°†æ— æ³•è½¬æ¢çš„å€¼è®¾ä¸ºNaT

                # å–æœ€æ—©å’Œæœ€æ™šçš„æ—¶é—´
                time_dict = {
                    'å¼€å§‹æ—¶é—´': group['å¼€å§‹æ—¶é—´'].min() if not group['å¼€å§‹æ—¶é—´'].empty else None,
                    'ç»“æŸæ—¶é—´': group['ç»“æŸæ—¶é—´'].max() if not group['ç»“æŸæ—¶é—´'].empty else None
                }

                # å°†æ‰€æœ‰å­—å…¸åˆå¹¶æˆä¸€ä¸ª
                group_dict = {**string_dict, **numeric_dict, **single_value_list_dict,
                              **multi_value_list_dict, **time_dict,**max_value_dict}

                return pd.Series(group_dict)

            # åˆ†ç»„å¹¶åº”ç”¨ aggregate_rows å‡½æ•°
            aggregated_data = non_idle_data.groupby('key_numbers').apply(aggregate_rows).reset_index()

            # åˆ é™¤ä¸å†éœ€è¦çš„åˆ—
            aggregated_data = aggregated_data.drop(columns=['key_numbers'])

        # å°†åŒ…å«'idle'çš„æ–‡ä»¶æ·»åŠ åˆ°ç»“æœä¸­
        idle_data = all_data[all_data['æ–‡ä»¶å'].str.contains('idle', na=False)]


        if aggregated_data.empty:
            merged_data = idle_data
        else:

            merged_data = pd.concat([aggregated_data, idle_data], ignore_index=True)

        # åˆå¹¶åçš„æ•°æ®é›†ç”Ÿæˆåºå·
        merged_data['åºå·'] = range(1, len(merged_data) + 1)

    # Configure grid options using GridOptionsBuilder
    builder = GridOptionsBuilder.from_dataframe(all_data)
    builder.configure_pagination(enabled=True)
    builder.configure_selection(selection_mode='single', use_checkbox=True)
    grid_options = builder.build()


    st.write("æ•°æ®æ±‡æ€»ï¼š")
    ag_grid = AgGrid(merged_data, gridOptions=grid_options)

    if st.button('ç­›é€‰æ•°æ®'):
        filtered_data = []

        for index, row in all_data.iterrows():
            # è§£æåœæ­¢ç²¾åº¦ï¼ˆåé€€å’Œå‰è¿›ï¼‰
            backward_accuracies = [float(acc) for acc in row['åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)'].split(';') if acc]
            forward_accuracies = [float(acc) for acc in row['åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)'].split(';') if acc]

            # è§£æç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€å’Œå‰è¿›ï¼‰
            backward_lateral_deviations = [float(dev) for dev in row['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)'].split(';') if dev]
            forward_lateral_deviations = [float(dev) for dev in row['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)'].split(';') if dev]

            # è§£æç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€å’Œå‰è¿›ï¼‰
            backward_heading_deviations = [float(dev) for dev in row['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)'].split(';') if dev]
            forward_heading_deviations = [float(dev) for dev in row['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)'].split(';') if dev]

            # è§£æç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ã€ç»ˆç‚¹è·¯çº¿å·ã€ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆåé€€å’Œå‰è¿›ï¼‰
            backward_end_state_infos = row['ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆåé€€ï¼‰'].split(';') if pd.notnull(row['ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆåé€€ï¼‰']) else []
            forward_end_state_infos = row['ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆå‰è¿›ï¼‰'].split(';') if pd.notnull(row['ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆå‰è¿›ï¼‰']) else []
            backward_end_route_numbers = row['ç»ˆç‚¹è·¯çº¿å·ï¼ˆåé€€ï¼‰'].split(';') if pd.notnull(row['ç»ˆç‚¹è·¯çº¿å·ï¼ˆåé€€ï¼‰']) else []
            forward_end_route_numbers = row['ç»ˆç‚¹è·¯çº¿å·ï¼ˆå‰è¿›ï¼‰'].split(';') if pd.notnull(row['ç»ˆç‚¹è·¯çº¿å·ï¼ˆå‰è¿›ï¼‰']) else []
            backward_end_route_types = row['ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆåé€€ï¼‰'].split(';') if pd.notnull(row['ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆåé€€ï¼‰']) else []
            forward_end_route_types = row['ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆå‰è¿›ï¼‰'].split(';') if pd.notnull(row['ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆå‰è¿›ï¼‰']) else []


            # æ£€æŸ¥æ˜¯å¦æœ‰å€¼è¶…å‡ºèŒƒå›´ï¼Œå¹¶è®°å½•ç›¸å…³ä¿¡æ¯
            out_of_range_info = {}
            if row['åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)'] is not None and row['åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)'] != '':
                if (any(acc > 20 for acc in backward_accuracies) or any(
                        acc < -20 for acc in backward_accuracies)):
                    out_of_range_info['åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)'] = row['åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)']
                    out_of_range_info['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)'] = row['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)']
                    out_of_range_info['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)'] = row['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)']
            if row['åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)'] is not None and row['åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)'] != '':
                if (any(acc > 20 for acc in forward_accuracies) or any(
                        acc < -20 for acc in forward_accuracies)):
                    out_of_range_info['åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)'] = row['åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)']
                    out_of_range_info['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)'] = row['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)']
                    out_of_range_info['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)'] = row['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)']
            if row['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)'] is not None and row['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)'] != '':
                if (any(dev > 2 for dev in backward_heading_deviations) or any(
                        dev < -2 for dev in backward_heading_deviations)):
                    if 'åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)' not in out_of_range_info:
                        out_of_range_info['åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)'] = row['åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)']
                    if 'ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)' not in out_of_range_info:
                        out_of_range_info['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)'] = row['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)']
                    out_of_range_info['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)'] = row['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)']
            if row['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)'] is not None and row['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)'] != '':
                if (any(dev > 2 for dev in forward_heading_deviations) or any(
                        dev < -2 for dev in forward_heading_deviations)):
                    if 'åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)' not in out_of_range_info:
                        out_of_range_info['åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)'] = row['åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)']
                    if 'ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)' not in out_of_range_info:
                        out_of_range_info['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)'] = row['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)']
                    out_of_range_info['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)'] = row['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)']
            if row['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)'] is not None and row['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)'] != '':
                if (any(dev > 20 for dev in backward_lateral_deviations) or any(
                        dev < -20 for dev in backward_lateral_deviations)):
                    if 'åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)' not in out_of_range_info:
                        out_of_range_info['åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)'] = row['åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)']
                    if 'ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)' not in out_of_range_info:
                        out_of_range_info['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)'] = row['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)']
                    out_of_range_info['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)'] = row['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)']
            if row['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)'] is not None and row['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)'] != '':
                if (any(dev > 20 for dev in forward_lateral_deviations) or any(
                        dev < -20 for dev in forward_lateral_deviations)):
                    if 'åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)' not in out_of_range_info:
                        out_of_range_info['åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)'] = row['åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)']
                    if 'ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)' not in out_of_range_info:
                        out_of_range_info['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)'] = row['ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)']
                    out_of_range_info['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)'] = row['ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)']


            if out_of_range_info:  # å¦‚æœæœ‰è¶…å‡ºèŒƒå›´çš„æ•°æ®ï¼Œåˆ™æ·»åŠ åˆ°ç­›é€‰ç»“æœä¸­

                if 'åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)' in out_of_range_info and row['åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)'] is not None and row[
                    'åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)'] != '':
                    if backward_end_state_infos:
                        out_of_range_info['ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆåé€€ï¼‰'] = ';'.join(backward_end_state_infos)
                    if backward_end_route_numbers:
                        out_of_range_info['ç»ˆç‚¹è·¯çº¿å·ï¼ˆåé€€ï¼‰'] = ';'.join(backward_end_route_numbers)
                    if backward_end_route_types:
                        out_of_range_info['ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆåé€€ï¼‰'] = ';'.join(backward_end_route_types)

                        # å‰è¿›çš„ç›¸å…³æ•°æ®
                if 'åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)' in out_of_range_info and row['åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)'] is not None and row[
                    'åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)'] != '':
                    if forward_end_state_infos:
                        out_of_range_info['ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆå‰è¿›ï¼‰'] = ';'.join(forward_end_state_infos)
                    if forward_end_route_numbers:
                        out_of_range_info['ç»ˆç‚¹è·¯çº¿å·ï¼ˆå‰è¿›ï¼‰'] = ';'.join(forward_end_route_numbers)
                    if forward_end_route_types:
                        out_of_range_info['ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆå‰è¿›ï¼‰'] = ';'.join(forward_end_route_types)

                filtered_data.append({'åºå·': index, 'æ–‡ä»¶å': row['æ–‡ä»¶å'], **out_of_range_info})



        all_columns = [
            'åºå·', 'æ–‡ä»¶å',
            'åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)', 'ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)', 'ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)',
            'åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)', 'ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)', 'ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)',
            'ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆåé€€ï¼‰', 'ç»ˆç‚¹è·¯çº¿å·ï¼ˆåé€€ï¼‰', 'ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆåé€€ï¼‰',
            'ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆå‰è¿›ï¼‰', 'ç»ˆç‚¹è·¯çº¿å·ï¼ˆå‰è¿›ï¼‰', 'ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆå‰è¿›ï¼‰'
        ]


        actual_columns = []

        if filtered_data:

            actual_columns = [col for col in all_columns if col in filtered_data[0].keys()]

        # è°ƒæ•´åˆ—çš„é¡ºåº
        adjusted_columns = []
        if actual_columns:
            for col in actual_columns:
                if col == 'ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)':
                    # åœ¨â€œç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰ï¼ˆÂ°ï¼‰â€ä¹‹åæ’å…¥ç›¸å…³åˆ—
                    adjusted_columns.append(col)
                    adjusted_columns.extend([
                        'ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆåé€€ï¼‰',
                        'ç»ˆç‚¹è·¯çº¿å·ï¼ˆåé€€ï¼‰',
                        'ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆåé€€ï¼‰'
                    ])
                elif col not in [
                    'ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆåé€€ï¼‰',
                    'ç»ˆç‚¹è·¯çº¿å·ï¼ˆåé€€ï¼‰',
                    'ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆåé€€ï¼‰'
                ]:
                    adjusted_columns.append(col)
        else:
            adjusted_columns = []


        filtered_df = pd.DataFrame(filtered_data, columns=adjusted_columns)

        # æ£€æŸ¥ç­›é€‰ç»“æœæ˜¯å¦ä¸ºç©º
        if filtered_df.empty:
            st.write('ç²¾åº¦ç¬¦åˆæ ‡å‡†')
        else:
            # æ˜¾ç¤ºç­›é€‰ç»“æœ
            st.write('ç­›é€‰ç»“æœï¼š')
            st.write(filtered_df)


    # Display AgGrid
    # åˆ—ååˆ—è¡¨ï¼Œè¿™äº›åˆ—å°†è¢«ç‰¹æ®Šå¤„ç†å¹¶ç»˜åˆ¶æ•£ç‚¹å›¾
    scatter_plot_columns = [
        'åœæ­¢ç²¾åº¦ï¼ˆåé€€ï¼‰(mm)',
        'ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆåé€€ï¼‰(mm)',
        'åœæ­¢ç²¾åº¦ï¼ˆå‰è¿›ï¼‰(mm)',
        'ç»ˆç‚¹æ¨ªå‘åå·®ï¼ˆå‰è¿›ï¼‰(mm)',

    ]

    scatter_plot_angle_columns = [
        'ç»ˆç‚¹èˆªå‘åå·®ï¼ˆåé€€ï¼‰(Â°)',
        'ç»ˆç‚¹èˆªå‘åå·®ï¼ˆå‰è¿›ï¼‰(Â°)'
    ]

    # ç´¢å¼•æ˜¯æ•°å­—ï¼Œå°†å…¶è½¬æ¢ä¸ºâ€œä»»åŠ¡Nâ€æ ¼å¼
    merged_data.index = ["ä»»åŠ¡" + str(i + 1) for i in merged_data.index]

    # åˆ—å‡ºéœ€è¦ä»é€‰æ‹©æ¡†ä¸­æ’é™¤çš„åˆ—å
    excluded_columns = [
        'åºå·', 'æ–‡ä»¶å','SNå·' ,'å¼€å§‹æ—¶é—´', 'ç»“æŸæ—¶é—´', 'æ•…éšœç¼–å·', 'æ•…éšœå‡ºç°æ—¶é—´æ®µ',
        'ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆåé€€ï¼‰', 'ç»ˆç‚¹è·¯çº¿å·ï¼ˆåé€€ï¼‰', 'ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆåé€€ï¼‰',
        'ç»ˆç‚¹çŠ¶æ€ä¿¡æ¯ï¼ˆå‰è¿›ï¼‰', 'ç»ˆç‚¹è·¯çº¿å·ï¼ˆå‰è¿›ï¼‰', 'ç»ˆç‚¹è·¯çº¿ç±»å‹ï¼ˆå‰è¿›ï¼‰'
    ]

    # ä» all_data.columns ä¸­æ’é™¤è¿™äº›åˆ—ï¼Œå¾—åˆ°ä¸€ä¸ªæ–°çš„åˆ—ååˆ—è¡¨
    selectable_columns = [col for col in merged_data.columns if col not in excluded_columns]

    # ä½¿ç”¨ç­›é€‰åçš„åˆ—ååˆ—è¡¨åˆ›å»ºé€‰æ‹©æ¡†
    selected_column = st.sidebar.selectbox('é€‰æ‹©åˆ—ä»¥ç»˜åˆ¶å›¾è¡¨', selectable_columns)


    # å¦‚æœé€‰æ‹©äº†ä¸€åˆ—ï¼Œåˆ™æ ¹æ®åˆ—åç»˜åˆ¶ç›¸åº”çš„å›¾è¡¨

    if selected_column:
        if selected_column in scatter_plot_columns:

            interval_counts = {
                '-40ä»¥ä¸‹': 0,
                '-40åˆ°-20': 0,
                '-20åˆ°0': 0,
                '0åˆ°20': 0,
                '20åˆ°40': 0,
                '40ä»¥ä¸Š': 0
            }


            for index, row in merged_data.iterrows():

                values_str = str(row[selected_column]).split(';')
                for value_str in values_str:

                    value_str = value_str.strip()
                    if not value_str or not value_str.replace('.', '', 1).replace('-', '', 1).isdigit():
                        continue
                    value = float(value_str)

                    # Update interval counter
                    if value < -40:
                        interval_counts['-40ä»¥ä¸‹'] += 1
                    elif -40 <= value < -20:
                        interval_counts['-40åˆ°-20'] += 1
                    elif -20 <= value < 0:
                        interval_counts['-20åˆ°0'] += 1
                    elif 0 <= value < 20:
                        interval_counts['0åˆ°20'] += 1
                    elif 20 <= value <= 40:
                        interval_counts['20åˆ°40'] += 1
                    else:
                        interval_counts['40ä»¥ä¸Š'] += 1


            labels = list(interval_counts.keys())
            values = list(interval_counts.values())


            total_count = sum(values)

            # è®¡ç®—-20åˆ°0å’Œ0åˆ°20çš„ç™¾åˆ†æ¯”
            range_20_to_0_percent = (interval_counts['-20åˆ°0'] + interval_counts[
                '0åˆ°20']) / total_count * 100 if total_count > 0 else 0

            # è¯„çº§é€»è¾‘
            if range_20_to_0_percent > 70:
                rating = 'ä¼˜ç§€'
            elif 40 <= range_20_to_0_percent <= 70:
                rating = 'è‰¯å¥½'
            elif 20 <= range_20_to_0_percent < 40:
                rating = 'ä¸­ç­‰'
            else:
                rating = 'è¾ƒå·®'

            # æ‰“å°è¯„çº§
            print(f"è¯„çº§: {rating}")


            fig = go.Figure(data=[go.Pie(labels=labels, values=values)])
            fig.update_layout(title_text=f'{selected_column} (è¯„çº§: {rating})')

            # æ˜¾ç¤ºé¥¼çŠ¶å›¾
            st.plotly_chart(fig)

        elif selected_column in scatter_plot_angle_columns:

            interval_counts = {
                '-4ä»¥ä¸‹': 0,
                '-4åˆ°-2': 0,
                '-2åˆ°0': 0,
                '0åˆ°2': 0,
                '2åˆ°4': 0,
                '4ä»¥ä¸Š': 0
            }


            for index, row in merged_data.iterrows():

                values_str = str(row[selected_column]).split(';')
                for value_str in values_str:

                    value_str = value_str.strip()
                    if not value_str or not value_str.replace('.', '', 1).replace('-', '', 1).isdigit():
                        continue
                    value = float(value_str)


                    if value < -4:
                        interval_counts['-4ä»¥ä¸‹'] += 1
                    elif -4 <= value < -2:
                        interval_counts['-4åˆ°-2'] += 1
                    elif -2 <= value < 0:
                        interval_counts['-2åˆ°0'] += 1
                    elif 0 <= value < 2:
                        interval_counts['0åˆ°2'] += 1
                    elif 2 <= value <= 4:
                        interval_counts['2åˆ°4'] += 1
                    else:
                        interval_counts['4ä»¥ä¸Š'] += 1


            labels = list(interval_counts.keys())
            values = list(interval_counts.values())


            total_count = sum(values)

            # è®¡ç®—-2åˆ°0å’Œ0åˆ°2çš„ç™¾åˆ†æ¯”
            range_20_to_0_percent = (interval_counts['-2åˆ°0'] + interval_counts[
                '0åˆ°2']) / total_count * 100 if total_count > 0 else 0

            # è¯„çº§é€»è¾‘
            if range_20_to_0_percent > 70:
                rating = 'ä¼˜ç§€'
            elif 40 <= range_20_to_0_percent <= 70:
                rating = 'è‰¯å¥½'
            elif 20 <= range_20_to_0_percent < 40:
                rating = 'ä¸­ç­‰'
            else:
                rating = 'è¾ƒå·®'


            # æ‰“å°è¯„çº§
            print(f"è¯„çº§: {rating}")


            fig = go.Figure(data=[go.Pie(labels=labels, values=values)])
            fig.update_layout(title_text=f'{selected_column} (è¯„çº§: {rating})')

            # æ˜¾ç¤ºé¥¼çŠ¶å›¾
            st.plotly_chart(fig)

        else:
            # å¯¹äºéé¥¼çŠ¶å›¾åˆ—ï¼Œç»˜åˆ¶æŠ˜çº¿å›¾
            fig = go.Figure(data=go.Scatter(x=merged_data.index, y=merged_data[selected_column], mode='lines'))
            fig.update_layout(title_text=f'{selected_column}')
            st.plotly_chart(fig)

    # è¿è¡Œ Streamlit åº”ç”¨
if __name__ == '__main__':
    st.write('ğŸŒˆ Welcome! ğŸŒˆ')